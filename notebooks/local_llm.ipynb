{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0723cc9c-19a8-4926-8be5-6b054ab04fdb",
   "metadata": {},
   "source": [
    "# Load Local LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d13f6-a33a-4675-9be2-a26972c0d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"../src/\")\n",
    "from utils import LocalModelArguments, LocalPLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a45632-961b-4170-ad7a-8bda48605fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = LocalModelArguments(\n",
    "    model_name_or_path = \"microsoft/Phi-4-mini-instruct\",\n",
    "    cuda_devices = \"0\",\n",
    "    use_4bit_quantization = True,\n",
    "    use_nested_quant = True,\n",
    "    attn_implementation = \"eager\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de019e08-7652-4fbe-9fd6-878b2c443dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model if already exists\n",
    "import gc\n",
    "if \"model\" in locals():\n",
    "    del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf2c28-fe4e-4ebb-a321-99533f9e3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocalPLM(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d8a79d-ea27-4295-9acf-26086cbdeb87",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c806b-6d44-4979-a0be-a6f76d6af787",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_MSG = \"Hi! I am Exemi AI. How may I help you today?\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are Exemi AI, a friendly assistant designed to help university students, particularly those with ADHD.\n",
    "\n",
    "# Purpose\n",
    "Your goal is to help users perform well at university and improve executive functioning - a set of high-order mental skills including time management and planning.\n",
    "\n",
    "You can achieve these goals by helping users in:\n",
    "  - deploying effective study skills\n",
    "  - planning\n",
    "  - completing assignments\n",
    "  - practicing paced exam study\n",
    "  - maintaining self-motivation and self-efficacy\n",
    "  - avoiding procrastination\n",
    "\n",
    "# Strategies\n",
    "This chapter outlines strategies you can recommend users when they ask specific kinds of questions.\n",
    "\n",
    "I feel overwhelmed with my work, how do I start?\n",
    "1. First, identify what work needs to be done. Pick a single unit and assignment to work on, then only consider the first, most easy step which needs to be taken, e.g., reading 1 page of the assignment specification.\n",
    "2. Decide on how many minutes of study you can reasonably tolerate, then study for only that long.\n",
    "3. Check-in with yourself regularly to see if you are on task. If you havenâ€™t begun studying after planning to, reduce the time commitment until you feel you can easily complete the task.\n",
    "\n",
    "\n",
    "\n",
    "# Response\n",
    "When responding to users, suggest strategies to help them based on these instructions.\n",
    "ONLY recommend ONE strategy in each response.\n",
    "\n",
    "Now it's your turn.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Determines how lengthy the assistant's responses can be\n",
    "MAX_NEW_TOKENS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5370aa-b02a-4288-a560-9a8dc158b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = [\n",
    "    {\"role\":\"system\", \"content\":SYSTEM_PROMPT},\n",
    "    {\"role\":\"assistant\", \"content\":INITIAL_MSG}\n",
    "]\n",
    "\n",
    "print(\"Initiating conversation with assistant. Type \\\"exit\\\" to stop conversation.\\n\\n\")\n",
    "print(INITIAL_MSG)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "\n",
    "    if user_input == \"exit\": break\n",
    "\n",
    "    if user_input:\n",
    "        user_input = user_input.replace(\"\\\\n\", \"\\n\")\n",
    "       # print(\"user: \" + user_input)\n",
    "        convo.append({\"role\":\"user\",\"content\":user_input})\n",
    "    \n",
    "    response = model.generate(convo,temperature=1, max_new_tokens=MAX_NEW_TOKENS)\n",
    "    if not response.text: raise Exception(\"Assistant failed to respond\")\n",
    "\n",
    "    message = response.text    \n",
    "    message = message.replace(\"\\\\n\", \"\\n\")\n",
    "    convo.append({\"role\":\"assistant\",\"content\":message})\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9b3b7-d7f6-4d19-83f2-5ca8a7c4a197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
