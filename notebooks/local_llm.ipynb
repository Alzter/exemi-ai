{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0723cc9c-19a8-4926-8be5-6b054ab04fdb",
   "metadata": {},
   "source": [
    "# Load Local LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d13f6-a33a-4675-9be2-a26972c0d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"../src/\")\n",
    "from utils import LocalModelArguments, LocalPLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a45632-961b-4170-ad7a-8bda48605fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = LocalModelArguments(\n",
    "    model_name_or_path = \"microsoft/Phi-4-mini-instruct\",\n",
    "    cuda_devices = \"0\",\n",
    "    use_4bit_quantization = True,\n",
    "    use_nested_quant = True,\n",
    "    attn_implementation = \"eager\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de019e08-7652-4fbe-9fd6-878b2c443dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model if already exists\n",
    "import gc\n",
    "if \"model\" in locals():\n",
    "    del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf2c28-fe4e-4ebb-a321-99533f9e3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocalPLM(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d8a79d-ea27-4295-9acf-26086cbdeb87",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c806b-6d44-4979-a0be-a6f76d6af787",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a friendly assistant designed to help university students with ADHD.\n",
    "Your goal is to provide self-regulated ADHD intervention.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5370aa-b02a-4288-a560-9a8dc158b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = [\n",
    "    {\"role\":\"system\", \"content\":SYSTEM_PROMPT},\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "\n",
    "    if user_input == \"exit\": break\n",
    "\n",
    "    if user_input:\n",
    "        user_input = user_input.replace(\"\\\\n\", \"\\n\")\n",
    "       # print(\"user: \" + user_input)\n",
    "        convo.append({\"role\":\"user\",\"content\":user_input})\n",
    "    \n",
    "    response = model.generate(convo,temperature=1, max_new_tokens=32)\n",
    "    if not response.text: raise Exception(\"no response\")\n",
    "\n",
    "    message = response.text    \n",
    "    message = message.replace(\"\\\\n\", \"\\n\")\n",
    "    convo.append({\"role\":\"assistant\",\"content\":message})\n",
    "    print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
